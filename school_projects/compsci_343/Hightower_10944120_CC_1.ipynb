{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVvWPLtFlM76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da182918-9b77-4f57-a43d-22650203ca7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's check the weather at the courts today...\n",
            "It looks like there's a good chance the sun is out today...\n",
            "Seems there's a chance of snow...\n",
            "It might hail...\n",
            "It's still a good day for tennis. Let's grab our rackets.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "# This is a short program that decides, based on the randomized input data, whether to go\n",
        "# and play tennis today. I hope this illustrates how a very basic decision tree might work\n",
        "# with the first main split being whether or not the indoor court is open, which is the best\n",
        "# deciding factor of if one should consider the weather when playing tennis.\n",
        "# The other factors come in after that and a conclusion can be reached based on the various\n",
        "# splits on weather.\n",
        "chance_of_rain = random.randint(0, 100)\n",
        "chance_of_sun = random.randint(0, 100)\n",
        "chance_of_hail = random.randint(0, 100)\n",
        "chance_of_sleet = random.randint(0, 100)\n",
        "chance_of_snow = random.randint(0, 100)\n",
        "chance_of_cloudy = random.randint(0, 100)\n",
        "good_partner = random.randint(0, 1)\n",
        "indoor_court = random.choice([True, False])\n",
        "tennis_time = False\n",
        "negatives: int = 0\n",
        "while not tennis_time:\n",
        "    if indoor_court:\n",
        "        print(\"The indoor court is open!\")\n",
        "        print(\"It's a good day for tennis no matter the weather. Let's grab our rackets.\")\n",
        "        tennis_time = True\n",
        "    else:\n",
        "        print(\"Let's check the weather at the courts today...\")\n",
        "        if chance_of_sun > chance_of_cloudy:\n",
        "            print(\"It looks like there's a good chance the sun is out today...\")\n",
        "            negatives = negatives - 1\n",
        "        if good_partner > 0:\n",
        "            print(\"I'm looking forward to playing with my friend...\")\n",
        "            negatives = negatives - good_partner\n",
        "        if chance_of_snow > 30:\n",
        "            print(\"Seems there's a chance of snow...\")\n",
        "            negatives = negatives + 1\n",
        "        if chance_of_rain > 50:\n",
        "            print(\"There's more than a coin flip's chance of rain...\")\n",
        "            negatives = negatives + 1\n",
        "        if chance_of_sleet > 40:\n",
        "            print(\"There's sleet in the forecast...\")\n",
        "            negatives = negatives + 1\n",
        "        if chance_of_hail > 20:\n",
        "            print(\"It might hail...\")\n",
        "            negatives = negatives + 1\n",
        "        if negatives > 1:\n",
        "            print(\"I'm not sure about the weather, lets stay in and play checkers.\")\n",
        "            tennis_time = True\n",
        "        else:\n",
        "            print(\"It's still a good day for tennis. Let's grab our rackets.\")\n",
        "            tennis_time = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Trees**\n",
        "\n",
        "\n",
        "\n",
        "*   Decision trees are often used for classification tasks, figuring out what a given thing is and where to sort it.\n",
        "*   The trees are often organized in such a way that one starts out in the roots of the tree and progresses towards one of the many leaves, which represent the endpoints\n",
        "* Trees begin with a set of base conditions and then travel down different paths based on the answers which given data provides until it reaches a definite conclusion, or the data cannot give a satisfactory answer\n",
        "* Decision trees can come in a variety of configurations. Some only diverge once they reach one of the 'leaves' of the tree. Some allow divergence\n",
        "* Trees are often used because they are both easily understandable and because they can be converted quickly into statements of code. E.g. true/false\n",
        "* Decision trees are usually made into a model like a flow chart\n",
        "* One way to eliminate noise and arrive at a more accurate conclusion is to refine the way that the tree prunes itself. That is, how it decides which path is the best one to continue down\n",
        "* One of the larger applications for this approach to data analysis is in education. Predicting which students are likely to succeed and which are likely to fail given past indicators, so that resources can be made available to ensure that students have what they need to succeed and issues within the educational sphere can be identified and taken care of before they reach a crisis point\n",
        "* Decision trees operate much like a taxonomical classification system, where at each level it has to decide what is the best splitting attribute. Much like how at each level of the animal kingdom, there must be a decision about how certain creatures are different from other ones. How a mammal is different from a reptile. How a mammal like a dog is different from a mammal like a cat. So on, so forth.\n",
        "* Decision tree growth can be made faster by either operating with a less complex version of the model that would encompass all the data, or by using a better search. The less complex model approach negatively impacts the accuracy of the final results. Sometimes a refined search can give better times without impacting the accuracy of final results, but it is difficult to make it functional for a wide variety of data sets\n",
        "* Drawbacks of the decision tree is that it requires the data to be sorted by all of its numerical attributes when a node needs to be split.\n",
        "* Two ways to alleviate the need to sort the data each time for a split are as follows. We can pre-sort the data so that it is easier for the decision tree to process and come to its conclusion, or we can use approximations made by sampling particularly relevant portions or constructing histograms\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qKelus_alS1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reference Sources**\n",
        "\n",
        "https://staff.icar.cnr.it/manco/Teaching/2006/datamining/articoli/Freund_Atrees.pdf\n",
        "\n",
        "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=c8ac945a377779c5ca24ebae20799a5aa8f5c601\n",
        "\n",
        "https://cdn.aaai.org/AAAI/2006/AAAI06-080.pdf\n",
        "\n",
        "https://www.jmlr.org/papers/volume11/ben-haim10a/ben-haim10a.pdf"
      ],
      "metadata": {
        "id": "NNo1-F6TF5Nh"
      }
    }
  ]
}