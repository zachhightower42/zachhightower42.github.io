- Chapter 7: Section 7.1.2, Computer Models
    
- Description
    
    --Be able to describe what a computer model is, and why they can be beneficial.
    
    --What are some factors that affect the accuracy of models? What are the non-technical factors that affect models?
    
    --Read the [Science](https://www.science.org/doi/10.1126/sciadv.aao5580) article reporting a study of the COMPAS recidivism prediction software. What were the results of the study?
    
    --What are the false positive/false negative percentages of COMPAS in relation to black or white defendants?
    
    --Discuss the ethics of judges using computer models to predict the likelihood of repeat offense (recidivism).
# Reading
1. A computer model is a model of a process in reality that has various simplifications that allow it to be run faster than the actual process takes. 
2. Model accuracy is affected by how well the actual process is understood by those designing the model. How complete and accurate the data that is being used to design the model is. How the simplifications and assumptions within the model have been made. E.g. If an assumption that the model depends on is erroneous or changes the problem drastically, the model is essentially useless for making any conclusions. 
 3. The results of the study suggest that there is no significant ability for COMPAS to measure actual recidivism rates in a way that is better than simpler models, or fully human driven assessment. The actual improvement that could be pointed to is within the margin of error such that it could be entirely due to random chance that it performs better than the simple two factor model for gauging recidivism. 
 4. The false positives that are generated by black defendants are about 28 percent or so. Roughly the same amount of false positives generated by black defendants are seen in the false negatives that are generated by the white defendants. This suggests the that system is racially biased, as the articles criticizing COMPAS suggest.
5. Using a system to gauge recidivism when it has such clear issues coming to any usable conclusion with the data fed into it is a bad idea. With human assessment we do not have the same amount of faith that would be present in machines, there could be some measure of successful appeal there. With machines there is the clear ability of those using them to point to the machines as being infallible, due to the fact that they only do what they are told. This does not necessarily mean that the machine has been told the correct thing to do, though. As such, we end up in a situation where machines are used to launder the bad opinions and conclusions of their makers. 

# Actual takeaway
Using a system to gauge recidivism when it has such clear issues coming to any usable conclusion with the data fed into it is a bad idea. With human assessment we do not have the same amount of faith that would be present in machines, there could be some measure of successful appeal there. With machines there is the clear ability of those using them to point to the machines as being infallible, due to the fact that they only do what they are told. This does not necessarily mean that the machine has been told the correct thing to do, though. As such, we end up in a situation where machines are used to launder the bad opinions and conclusions of their makers. 