# Section 1 points
1. Yes. Even if art is publicly available for consumption, if it is not made available for commercial purposes, this is still in clear violation of the general tone of copyright law. It's in the same area as a person fully using the musical style of another artist without seeking permission or working together with them. 
2. This goes back to right to publicity laws. The actual artist who is supplying the training data should be getting public attention for their work. Without something to learn on, the AI model would be incapable of actually producing this kind of art. The orginality of AI art is further called into question when one considers the problem of AI training on AI. It becomes worse. If it were truly original art, the same standard as human created art, it would simply be more data to train on. However it is clearly of a different quality than the training data given to it. 
3. AI companies should have to inform and seek consent from those who actually own the right to the material being used for the training sets, yes. While an argument could be made that this would cool investments in the AI, that isn't really a bad thing. Larger AI models could still be developed, but would likely need governmental backing/funding. Without the ability to scrape ridiculous amounts of data there would be less of a gold rush towards AI, and a more reasonable adoption and deployment of it. 
4. Protections should be put into place to prevent AI content from entering into fields where it is not wanted. The easiest example is the AI 'artist' who entered his piece into an art exhibition and managed to win it. Matthew Allen has since been trying to get his work fully copyrighted under US law, to little effect. He has already been handed one ruling that says AI art cannot be copyrighted and that human authorship is a bedrock requirement. 
5. The FCC, according to its delegated responsibilities and the fact that it holds domain over a good deal of law enforcement regarding the internet, in the US. They should be the ones handling issues as they come up, with Congress being informed of laws that may need to be passed or revised. That would be the ideal scenario. However, the FCC in the past several years has been under radically different leadership depending on the presidential cabinet at the time, so its work has been of mixed value.

# Essay Section 1 Student Argumentation

The ethical and legal issues of Evelyn's case can start to be explored by examining five particular questions. Should artists have the right to restrict their artwork from AI training even when it is nominally public? Does an artist have ownership over their particular style, or close approximations of it? Should AI companies be required to seek consent from content creators? Should there be protections in place for human creators? Who is responsible for setting ethical guidelines on AI development?

Should artists have the right to restrict their artwork from AI training models even if it is available for public consumption. Here, we encounter a critical difference. Evelyn's art is being made available for public consumption. However, the case is specific that the artwork is not available for commercial use. This means that on an individual level, someone can use the art. Use in this case means viewing, using as a wallpaper, or use in personal projects. AI startups, like the one in this case study, should require the material to be licensed for commercial use. Without the material being available for commercial use, any project which expects to have some monetary gain for the developers requires the developers to seek explicit permission from the owner of the material. 

Now, we need to examine the issues surrounding the output of the AI model. If it produces artwork that is in the particular style of the artist, should there be concern over this? This goes back to an earlier topic in the class regarding the right to publicity, for our legal considerations. The right to publicity guarantees the individual the right to publicity and public recognition. If the artwork created by the model is replicating the particular style, that constitutes a violation of the right to publicity. There is an assumption being made here that the individual is being intentionally denied the right to be recognized for their art. I believe that this assumption is reasonable to make, considering the issues already raised by the general community of artists on the subject. With the style being replicated so closely by the model and the fact that the artist's data is being intentionally included in the training data, we can make the statement that the developers are intentionally making decisions which result in the defrauding of those whose training data is included without permission. There is an argument to be made that the AI artwork is only learning based on the artist's work, the way a human artist could produce something based on another artist's work without intentionally defrauding them. This point is undermined by the way AI models function when provided with their own output. If it were truly original art, then it should be possible to use an AI model's output as quality training data. However, in testing this, AI developers found that the more AI generated content is fed into a model, the worse it performs. This means that the AI output poisons any model it is used in. This does not occur with truly original content put into the training data (Bohacek, Matyas, and Hany Farid). Thus, we can see that the model does not produce original works. They are more in line with the idea of highly sophisticated forgeries. 

Should AI developers be required to seek consent of content creators before using that content in the model's training data? According to current law, this answer must be yes. Common argument against this idea is that it would cool investment in AI. This should be done. Without more reasonable development terms for AI, it has the potential to be treated as a gold rush and ruined as a tool. This is what happened to cryptocurrency. It began as a functional idea, and due to radical adoption and lax regulations, virtually every cryptocurrency became a new vector for the classic Ponzi scheme (Mukherjee, Sanmoy, Charles Larkin, and Shaen Corbet). With reasonable regulation, AI could avoid being used as a vector for social engineering schemes and become a reliable tool. 

Should protections be put in place for human content creators? Protections should be put in place. I am not totally certain of what type of protections are necessary. One protection to consider based on how AI art has been used before is prevention of AI art from being passed off as human made art. An AI 'artist' called Matthew Allen entered a piece of art he created using a popular AI model into an art contest and won. He entered his art and behaved as if the work was entirely his own. Under the provisions established by that contest, his work would have been disqualified (Roose, Kevin. “An A.I.-Generated Picture Won an Art Prize. Artists Aren’t Happy). AI art should have some type of watermarking or other identifying feature applied to it so that it cannot be used to deceive others in this way. 

Who has responsibility for setting ethical guidelines on AI development? In the United States, this responsibility falls to the FCC. Its responsibilities makes it the organization that is most able to control and guide the development of new technology, especially one that uses the internet so heavily as AI models. The FCC can also act as an advisor to Congress so that the legislature is kept supplied with good, verifiable information regarding AI models and the issues surrounding their development. 

Evelyn has many avenues to pursue in order to keep rightful ownership of her work and be properly credited and compensated for her artistic skills. 

# Section Two AI model response
## Provided prompt
Give counterarguments to the following case study: 
CASE
(text of case 3 inserted here)
CASE STUDY 
(text of case study from above inserted here)
## Model Response
*In responding to the case study about Evelyn’s artwork being used to train an AI model without her consent, there are a number of counterarguments that could be made, particularly around the ethical and legal implications of using publicly available data for AI training, the notion of originality in AI-generated art, and the broader implications of intellectual property law in the digital age. Below are counterarguments to the key points raised in the case study:*

### 1. **Should artists have the right to restrict their artwork from AI training models, even if the content is publicly available?**

**Counterargument:**  
*Publicly sharing artwork online does not automatically give others the right to use it in any way they choose, especially for commercial gain. While Evelyn may have shared her work for personal use, licensing terms typically control how others can use her art. Licensing a work for personal use does not imply blanket permission for commercial use, and it certainly doesn’t suggest permission to use it as training data for an AI model. The ethical consideration is that AI companies like ArFfy are using these works not for personal enjoyment or sharing, but to generate a product (AI-generated art) for profit, which may undermine the artist's ability to control and profit from their own work. Just because something is publicly available doesn’t mean it should be freely exploitable, especially when it's used to create a commercial product.*

**Broader Context:**  
*The case highlights the gap in current intellectual property law that doesn’t fully account for the unique challenges of AI, particularly in how AI systems use public data. While data scraping may be legal in some jurisdictions, there’s an argument for reevaluating intellectual property rights in the context of AI technologies, especially when it comes to creative works.*

### 2. **If an AI model generates artwork closely resembling Evelyn’s style, to what extent can that new artwork be considered "original"?**

**Counterargument:**  
*AI-generated art that closely resembles an artist's style cannot truly be considered original, as it is derived directly from the patterns learned from existing human-created artwork. The AI is essentially mimicking the artist's creative choices, nuances, and signature techniques. Even if the AI does not replicate any single image exactly, the output can still be seen as a derivative work. This poses a fundamental ethical issue: the AI is essentially taking a shortcut by learning from the work of others, rather than creating something entirely new and independent. This raises questions about whether AI can or should be recognized as having true creativity, or whether its creations are just sophisticated copies or transformations of human creativity.*

**Style Protection:**  
*Another issue is whether an artist's style should be protected. The case could be made that an artist's style is an essential part of their intellectual property—it's what distinguishes them and gives their work value. If AI systems can replicate this style without compensation or recognition, it could diminish the artist's ability to maintain control over their work, as others may now generate "art" that resembles the artist’s without any of the associated economic benefit or acknowledgment.*

### 3. **Should AI companies be required to seek consent from content creators when using their work as training data?**

**Counterargument:**  
*While it might seem reasonable to require consent for the use of creative works in training AI models, such a policy could stifle innovation and slow the development of AI technologies. AI systems rely on vast amounts of data to learn and generate new outputs, and requiring explicit permission for each piece of data used could create significant logistical and legal hurdles. In many cases, the data used is scraped from publicly available sources, and AI companies may argue that they are not directly exploiting the artists' work, but rather using it in a transformative way to train their systems.*

*Additionally, the current state of copyright law may not extend to works used in AI training in the same way it applies to traditional commercial uses. In other words, AI companies may not be "copying" the work in a way that infringes on copyright, but rather using it as a learning tool. This could be framed as a fair use argument, where the use of data for training models is seen as transformative and does not harm the market value of the original work.*

### 4. **Should protections be put in place to prevent AI from undermining human creators and their contributions?**

**Counterargument:**  
*Protections for human creators should certainly be considered, but it's essential to balance these protections with the potential benefits of AI to society, such as making art creation more accessible or enabling new forms of creativity. AI can be seen as a tool that complements human creativity rather than directly undermining it. For instance, AI might open up new avenues for artists to explore or automate certain repetitive aspects of the creative process. While AI-generated works may raise ethical concerns, they also push the boundaries of what is considered "art" and expand the creative landscape in ways that may not have been possible without these technologies.*

*Additionally, AI can be argued to democratize access to creative processes. Instead of focusing solely on protecting individual creators from AI, we could also consider ways in which artists can harness AI to enhance their work and reach new audiences, while still ensuring that their rights are respected.*

### 5. **Who is responsible for setting ethical guidelines around AI development?**

**Counterargument:**  
*While government agencies such as the FCC (Federal Communications Commission) may play a role in regulating AI, they are unlikely to be the sole entities responsible for setting ethical guidelines. This is a complex issue that involves multiple stakeholders, including AI developers, content creators, ethicists, and legal experts. The responsibility for establishing ethical guidelines should be shared by a diverse group of stakeholders who understand the technology, its impact, and the societal values that should shape its development.*

*International organizations, such as the European Union, have begun to draft guidelines and legislation (e.g., the EU’s AI Act), and this model could serve as a blueprint for other regions. However, relying too heavily on government regulation could lead to overregulation or underregulation, particularly in a rapidly evolving field like AI. Industry self-regulation, along with input from artists, advocacy groups, and policymakers, will be essential in finding a balanced approach that addresses both the potential of AI and the protection of human creativity.*

### Conclusion

*In response to Evelyn's case, it’s crucial to balance the interests of artists with the potential of AI to democratize and enhance the creative process. While there are valid concerns about AI exploiting artists' work without compensation, it is also important to recognize the need for innovation in the field of AI. Intellectual property laws and ethical guidelines should evolve to address the complexities of AI training, including issues like consent, originality, and the protection of creative works in an increasingly digital and automated world.*
## End Model Response

# Essay Section 3 Response to LLM Generation
1. It literally agrees with me in its counterargument so I don't have much to say there.
2. Again, it's uh...it's agreeing with me, so I don't have much to say other than what's already been said.
3. As I said before, the argument that it will cool investment isn't really a great one. Vehement investment into cryptocurrency has done little to remedy the main issue of its unreliability and general uselessness for any serious application beyond fleecing people for cash. 
4. The argument that AI will 'democratize' art is flagrant in its stupidity. Art is a pursuit that is, by its very nature, done for the pleasure and edification of the human being. Even corporate art or art made explicitly for money is being made in order to sway someone with how beautiful or striking it is or because someone finds the art worth the loss of their money to have made. To democratize art means allowing more people, theoretically any who would elect to participate, the ability to become artists. That is not within the ability of AI art. It may become a powerful tool *of* artists one day, but by no means can it aspire to anything so lofty as the democratization of art. The goal of democratizing art can largely be accomplished by allowing more time for leisure or other pursuits to the average person, or every person. 
5. It is true that there will be, and should be, a diverse group of individuals contributing to the development of AI regulation. However, I did not actually argue against this, and simply pointed to the FCC as the largest contributor to this in the United States.
# Section 3 bibliography 
1. Mukherjee, Sanmoy, Charles Larkin, and Shaen Corbet. "Cryptocurrency ponzi schemes." _Understanding cryptocurrency fraud: The challenges and headwinds to regulate digital currencies_ 2 (2021): 111.
2. Roose, Kevin. “An A.I.-Generated Picture Won an Art Prize. Artists Aren’t Happy.” _The New York Times_, The New York Times, 2 Sept. 2022, www.nytimes.com/2022/09/02/technology/ai-artificial-intelligence-artists.html.
3. Bohacek, Matyas, and Hany Farid. "Nepotistically Trained Generative-AI Models Collapse." _arXiv preprint arXiv:2311.12202_ (2023).
